---
title: "El discurso de género en el Parlamento uruguayo"
subtitle: "________"
author: "    "
institute: "_WiDS Montevideo_"
date: "28 de abril de 2022"
output:
  xaringan::moon_reader:
    css: ["estilo.css"]
    self_contained: true
    lib_dir: libs
    nature:
      ratio: '16:9'
---
class: middle, left

<center>

![](avatar.jpg) 

**Soc. Elina Gómez**

_Docente Unidad de Métodos y Acceso a Datos (UMAD) - FCS/UdelaR_

elina.gomez@cienciassociales.edu.uy

www.elinagomez.com



---
class: middle, left

# Instalaciones previas

1. R y RStudio

- Instalar el R básico desde el repositorio CRAN: [Última versión R 4.1.3](https://cran.r-project.org/)
- [Instalar RStudio](https://www.rstudio.com/products/rstudio/download/)

(para ambos casos existen indicaciones para el sistema operativo específico)

---
class: middle, left

# Instalaciones previas

2. Librerías 

```{r eval=FALSE, message=FALSE, warning=FALSE}

#Instalo librerías
#De CRAN: 
#install.packages(c("speech","quanteda","dplyr","tidymodels","vip",
#"quanteda.textplots","RColorBrewer"))

#De GitHub: 
#remotes::install_github("Nicolas-Schmidt/puy")


#Cargo librerías
library(speech)
library(puy)
library(quanteda)
library(dplyr)
library(tidymodels)
library(vip)

```

---
class: middle, left

# Objetivo general

El **objetivo general** del trabajo es lograr un buen método de clasificación de texto que permita distinguir entre las intervenciones parlamentarias en la Cámara de representantes (unidad mínima de análisis) que planteen y discutan la temática de género para luego analizar mediante variables anexas, qué representantes, partidos, sectores son los que instalan la discusión en dicha materia. 


---
class: middle, left

# Pasos a seguir

1. **Obtención de la información**
2. **Limpieza del texto y matriz de términos**
3. **Clasificación: machine lerning y diccionario**
4. **Análisis de los datos**



---
class: chapter-slide

# 1. Obtención de la información


---
class: middle, left


Para la obtención de información, usaremos el paquete [speech](https://cran.r-project.org/web/packages/speech/index.html) el cual permite descargar las sesiones parlamentarias de forma fácil y ordenada, agregando a los discursos algunas variables anexas como la legislatura, el nombre, la fecha de la sesión, entre otras. 


---
class: middle, left

```{r eval=F, message=FALSE, warning=FALSE}

#Para obtener las url de las sesiones parlamentarias por rango temporal y cámara
# S Camara de Senadores
# D Camara de Representantes 
# A Asamblea General 
# C Comisión Permanente

urls = speech::speech_url(chamber  = "D",
            from        = "15-02-2015",
            to          = "15-06-2015")

intervenciones = speech::speech_build(urls)

```



Para agregar la etiqueta partidaria usamos el paquete [puy](https://github.com/Nicolas-Schmidt/puy) que cuenta con una base histórica de político/as uruguayos/as. 

```{r eval=F, message=FALSE, warning=FALSE}

# uso la función add_party

intervenciones = puy::add_party(intervenciones)

```



---
class: middle, left

Otra forma accesible sería descargar la base de forma manual con la aplicación: [speech App](https://bancodedatos-fcs.shinyapps.io/shiny_speech/)


---
class: middle, left

Para este taller vamos a utilizar la base de sesiones ya descargada correspondiente a la la legislatura pasada: __XLVIII (2015-2020)__, y a la cámara de Diputados/as, con etiqueta partidaria incorporada. Para entrenar el modelo, usaremos una base con intervenciones de la Comisión de Género del parlamento y otras Comisiones temáticas.  


```{r eval=F, message=FALSE, warning=FALSE}

load("Datos/intervenciones_2015_2020.RData")
load("Datos/com_genero.RData")

```


---
class: chapter-slide

# 2. Limpieza del texto y matriz de términos de la base de entrenamiento


---
class: middle, left


En primer lugar, quito las sentencias con menos de 13 palabras:


```{r eval=F, message=FALSE, warning=FALSE}

speech <- quanteda::corpus(com_genero,text_field = "speech")%>%
  quanteda::corpus_trim(what = "sentences",min_ntoken = 13) 
com_genero=cbind(docvars(speech),speech)

```


---
class: middle, left

Luego, armo la matriz de términos, haciendo limpieza de stopwords, puntuación, números y _podo_ la matriz. 

```{r eval=F, message=FALSE, warning=FALSE}

dfm_com_genero<- quanteda::dfm(quanteda::tokens(com_genero$speech,
                                    remove_punct = TRUE,
                                    remove_numbers = TRUE),
                                    tolower=TRUE,
                                    verbose = FALSE) %>%
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("spanish"), 
                                   tolower(com_genero$legislator),
                                   "señor","señora","presidente","presidenta"), 
                       min_nchar = 3)%>%
        quanteda::dfm_trim(min_termfreq = 60)

```


---
class: middle, left

Hago una nube de palabras para evaluar la segmentación. 

```{r eval=F, message=FALSE, warning=FALSE}

quanteda.textplots::textplot_wordcloud(quanteda::dfm_group(dfm_com_genero,groups = com_genero$genero), 
                                       min.count = 30, 
                                       max_words = 300,
                                       random.order = FALSE ,
                                       rot.per = .25,
                                       colors = RColorBrewer::brewer.pal(8,"Dark2"),
                                       comparison = TRUE)

```

---
class: chapter-slide

# 3. Clasificación: aprendizaje automático y diccionario


---
class: middle, left


Armo un data frame a partir de la matriz de términos y le agrego la variable  genero con: Si genero / No genero

```{r eval=F, message=FALSE, warning=FALSE}

dfm_com_genero_df <- dfm_com_genero %>%
  convert(to = "data.frame") %>%
  mutate(genero=docvars(dfm_com_genero, "genero"))

```

---
class: middle, left

Divido la base de entrenamiento en dos y entreno el modelo a la base _train_.

```{r eval=F, message=FALSE, warning=FALSE}

set.seed(123)
genero_split <- initial_split(dfm_com_genero_df, strata = genero)
genero_train <- training(genero_split)
genero_test <- testing(genero_split)

genero_rf <-  rand_forest(trees = 350, mode = "classification") %>%
  set_engine("ranger",importance = "impurity") %>%
  fit(genero ~ ., data = genero_train[, !(colnames(genero_train) %in% c("doc_id"))])

```



---
class: middle, left

Lo aplico a la sub base train en la cual entrené el modelo y evalúo métricas. 

```{r eval=F, message=FALSE, warning=FALSE}

genero_train = genero_rf %>%
  predict(genero_train) %>%
  bind_cols(genero_train)

library(vip)

##ploteo importantes
genero_rf%>%
  vip(num_features = 20)


table(genero_train$genero,genero_train$.pred_class)
metrics(genero_train,truth = genero, estimate = .pred_class)

```


---
class: middle, left

Luego lo aplico en la base de testeo. 

```{r eval=F, message=FALSE, warning=FALSE}

genero_test = genero_rf %>%
  predict(genero_test) %>%
  bind_cols(genero_test)

table(genero_test$genero,genero_test$.pred_class)
metrics(genero_test,truth = genero, estimate = .pred_class)


```

---
class: middle, left

Uso el modelo para predecir en la base grande, creo una matriz de términos en la base grande.

```{r eval=F, message=FALSE, warning=FALSE}

speech <- quanteda::corpus(intervenciones_2015_2020,text_field = "speech")%>%
  quanteda::corpus_trim(what = "sentences",min_ntoken = 13) 
diputados=cbind(docvars(speech),speech)

dfm_diputados<- quanteda::dfm(quanteda::tokens(diputados$speech,
                              remove_punct = TRUE,
                              remove_numbers = TRUE),
                               tolower=TRUE,
                               verbose = FALSE) %>%
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("spanish"), 
                                   tolower(com_genero$legislator),
                                   "señor","señora","presidente","presidenta"), 
                       min_nchar = 3)%>%
  quanteda::dfm_trim(min_termfreq = 20) ## no soy tan restrictiva

```


---
class: middle, left

Me quedo con las variables (palabras) comunes y aplico el modelo

```{r eval=F, message=FALSE, warning=FALSE}

dfm_diputados_df <- dfm_diputados %>%
  convert(to = "data.frame")

dfm_diputados_df[,setdiff(colnames(genero_train),colnames(dfm_diputados_df))]=0

dfm_diputados_df <- dfm_diputados_df %>%
  select(colnames(genero_train))%>%
 select(-.pred_class, -genero)

#Aplico el modelo, le agrego resto de variables y filtro por aquellas que clasifica como "Si genero"

dfm_diputados_df = genero_rf %>%
  predict(dfm_diputados_df) %>%
  bind_cols(dfm_diputados_df) %>%
  select(.pred_class)%>%
  bind_cols(diputados)%>%
  filter(.pred_class=="Si genero")

```

---
class: middle, left

Vuelvo a realizar una matriz de términos, con las intervenciones pre-clasificadas

```{r eval=F, message=FALSE, warning=FALSE}

dfm_sigenero<- quanteda::dfm(quanteda::tokens(dfm_diputados_df$speech,
                             remove_punct = TRUE,
                             remove_numbers = TRUE),
                              tolower=TRUE,
                              verbose = FALSE) %>%
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("spanish"), 
                                   tolower(dfm_diputados_df$legislator),
                                   "señor","señora","presidente","presidenta"), 
                       min_nchar = 3)

```

---
class: middle, left

Creo diccionario de "género" a partir de las 50 palabras más mencionadas en la matriz de términos de Comisión de género 


```{r eval=F, message=FALSE, warning=FALSE}

dicgenero <- dfm_com_genero %>%
quanteda::topfeatures(50,groups = genero)
dicgenero <- rownames(as.data.frame(dicgenero[[2]]))
dicgenero <-dictionary(list(genero=dicgenero))

```

---
class: middle, left

Aplico el diccionario y calculo un ratio que es la cantidad de palabras en el diccionario entre la cantidad de palabras totales. Me quedo con las intervenciones que tienen más de 5% de palabras vinculadas al tema.  


```{r eval=F, message=FALSE, warning=FALSE}

resultado_dic <- data.frame(dfm_lookup(dfm_sigenero,dictionary=dicgenero))

 df_sigenero = dfm_diputados_df %>%
  bind_cols(resultado_dic) %>%
  mutate(ratio=genero/words)%>%
   filter(ratio>=0.05)

```

---
class: chapter-slide

# 4. Análisis de los datos 

---
class: middle, left


Por sexo:

```{r eval=F, message=FALSE, warning=FALSE}

 #Grafico por sexo 
 
   genero=df_sigenero %>%
     mutate(sexo=ifelse(sex==1,"Varón","Mujer")) %>%
     group_by(sexo) %>%
     summarise(ratio= n()/length(unique(legislator2)))%>%
     ggplot(aes(x = reorder(sexo, -ratio) , y = ratio,group = 1)) + 
     geom_bar(size=1, stat="identity",fill = c("#e76363","#f09e9e"),width = 0.6) +
     scale_y_continuous(limits = c(0, 12))+ 
     theme(axis.text.x = element_text(size=10), 
           axis.text.y = element_text(size=10),
           axis.title.x=element_blank(),axis.title.y=element_blank())

```


---
class: middle, left

Por partido:

```{r eval=F, message=FALSE, warning=FALSE}

  #Grafico por partido 
   
   partido=df_sigenero %>%
     group_by(party_acron) %>%
     drop_na()%>%
     summarise(conteo=n())%>%
     ggplot(aes(x = reorder(party_acron, -conteo) , y = conteo,group = 1)) + 
     geom_bar(size=1, stat="identity",fill = c("#954342","#954342","#4a2524","#e76363","#bd5352","#6e3432"),width = 0.6) +
     #scale_y_continuous(limits = c(0, 12))+ 
     theme(axis.text.x = element_text(size=10), 
           axis.text.y = element_text(size=10),
           axis.title.x=element_blank(),axis.title.y=element_blank())

```

---
class: middle, left

Por legislador/a:

```{r eval=F, message=FALSE, warning=FALSE}

   #Grafico por legislador/a 

  legis=df_sigenero %>%
     count(legislator2)%>%
     drop_na()%>%
     top_n(n=10) %>%
     arrange(n)%>%
     ggplot(aes(x = reorder(legislator2, n) , y = n,group = 1)) + 
     geom_bar(size=1, stat="identity",fill = c("#954342"),width = 0.6) +
     scale_fill_gradient(low = "white", high = "red")+
     coord_flip()+
     theme(axis.text.x = element_text(size=10), 
           axis.text.y = element_text(size=10),
           axis.title.x=element_blank(),axis.title.y=element_blank())
```



---
class: chapter-slide

# Gracias!



